{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>_int_0</th>\n",
       "      <th>_int_1</th>\n",
       "      <th>_int_2</th>\n",
       "      <th>_int_3</th>\n",
       "      <th>_int_4</th>\n",
       "      <th>_int_5</th>\n",
       "      <th>_int_6</th>\n",
       "      <th>_int_7</th>\n",
       "      <th>_int_8</th>\n",
       "      <th>...</th>\n",
       "      <th>_lrc_127</th>\n",
       "      <th>_lrc_128</th>\n",
       "      <th>_lrc_129</th>\n",
       "      <th>_lrc_130</th>\n",
       "      <th>_lrc_131</th>\n",
       "      <th>_lrc_0</th>\n",
       "      <th>_lrc_1</th>\n",
       "      <th>_lrc_2</th>\n",
       "      <th>_lrc_3</th>\n",
       "      <th>_lrc_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>! .. عشان ما تنضربش على قفاك</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>2.384186e-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>!!شعراء إرهابيون</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>!búscalo! (look it up!): a quick reference gui...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>!exacto!: a practical guide to spanish grammar</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>!feliz navidad: celebrating a mexican christmas</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>2.285714e-01</td>\n",
       "      <td>2.571429e-01</td>\n",
       "      <td>2.285714e-01</td>\n",
       "      <td>1.428571e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486019</th>\n",
       "      <td>ｍな女王様と××したいってばよ [m na jousama to xx shitai tte...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486020</th>\n",
       "      <td>ｍの劣情 [m no retsujou]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486021</th>\n",
       "      <td>ｓａｍｕｒａｉ　ｄｅｅｐｅｒ　ｋｙｏ（１）</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486022</th>\n",
       "      <td>ｘｂｌａｄｅ（１０）</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>-1.490116e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486023</th>\n",
       "      <td>ｘｘｘアレルギー [xxx allergy]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.980232e-08</td>\n",
       "      <td>-2.980232e-08</td>\n",
       "      <td>-2.980232e-08</td>\n",
       "      <td>-2.980232e-08</td>\n",
       "      <td>-2.980232e-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1486024 rows × 265 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     title  _int_0  _int_1  \\\n",
       "0                             ! .. عشان ما تنضربش على قفاك       0       0   \n",
       "1                                         !!شعراء إرهابيون       0       0   \n",
       "2        !búscalo! (look it up!): a quick reference gui...       0       0   \n",
       "3           !exacto!: a practical guide to spanish grammar       0       0   \n",
       "4          !feliz navidad: celebrating a mexican christmas       0       0   \n",
       "...                                                    ...     ...     ...   \n",
       "1486019  ｍな女王様と××したいってばよ [m na jousama to xx shitai tte...       0       0   \n",
       "1486020                               ｍの劣情 [m no retsujou]       0       0   \n",
       "1486021                              ｓａｍｕｒａｉ　ｄｅｅｐｅｒ　ｋｙｏ（１）       0       0   \n",
       "1486022                                         ｘｂｌａｄｅ（１０）       0       0   \n",
       "1486023                             ｘｘｘアレルギー [xxx allergy]       0       0   \n",
       "\n",
       "         _int_2  _int_3  _int_4  _int_5  _int_6  _int_7  _int_8  ...  \\\n",
       "0             0       0       0       0       0       0       0  ...   \n",
       "1             0       0       0       0       0       0       0  ...   \n",
       "2             0       0       0       0       0       0       0  ...   \n",
       "3             0       0       0       0       0       0       0  ...   \n",
       "4             0       0       0       0       0       0       0  ...   \n",
       "...         ...     ...     ...     ...     ...     ...     ...  ...   \n",
       "1486019       0       0       0       0       0       0       0  ...   \n",
       "1486020       0       0       0       0       0       0       0  ...   \n",
       "1486021       0       0       0       0       0       0       0  ...   \n",
       "1486022       0       0       0       0       0       0       0  ...   \n",
       "1486023       0       0       0       0       0       0       0  ...   \n",
       "\n",
       "             _lrc_127      _lrc_128      _lrc_129      _lrc_130      _lrc_131  \\\n",
       "0        2.384186e-07  2.384186e-07  2.384186e-07  2.384186e-07  2.384186e-07   \n",
       "1       -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08   \n",
       "2       -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08   \n",
       "3       -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08   \n",
       "4        1.428571e-01  2.285714e-01  2.571429e-01  2.285714e-01  1.428571e-01   \n",
       "...               ...           ...           ...           ...           ...   \n",
       "1486019 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08   \n",
       "1486020 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08   \n",
       "1486021 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08   \n",
       "1486022 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08 -1.490116e-08   \n",
       "1486023 -2.980232e-08 -2.980232e-08 -2.980232e-08 -2.980232e-08 -2.980232e-08   \n",
       "\n",
       "         _lrc_0  _lrc_1  _lrc_2  _lrc_3  _lrc_4  \n",
       "0           NaN     NaN     NaN     NaN     NaN  \n",
       "1           NaN     NaN     NaN     NaN     NaN  \n",
       "2           NaN     NaN     NaN     NaN     NaN  \n",
       "3           NaN     NaN     NaN     NaN     NaN  \n",
       "4           NaN     NaN     NaN     NaN     NaN  \n",
       "...         ...     ...     ...     ...     ...  \n",
       "1486019     NaN     NaN     NaN     NaN     NaN  \n",
       "1486020     NaN     NaN     NaN     NaN     NaN  \n",
       "1486021     NaN     NaN     NaN     NaN     NaN  \n",
       "1486022     NaN     NaN     NaN     NaN     NaN  \n",
       "1486023     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[1486024 rows x 265 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"datasets/pre_computed_slopes.parquet\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>price</th>\n",
       "      <th>Shortlist/Longlist/Winner</th>\n",
       "      <th>ISBN-10</th>\n",
       "      <th>date</th>\n",
       "      <th>ISBN-13</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>Olive Kitteridge</td>\n",
       "      <td>Elizabeth Strout</td>\n",
       "      <td>Pulitzer Prize for Fiction</td>\n",
       "      <td>Winner</td>\n",
       "      <td>140006208X</td>\n",
       "      <td>4/20/2009</td>\n",
       "      <td>9.781400e+12</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>Tinkers</td>\n",
       "      <td>Paul Harding</td>\n",
       "      <td>Pulitzer Prize for Fiction</td>\n",
       "      <td>Winner</td>\n",
       "      <td>1446455998</td>\n",
       "      <td>4/12/2010</td>\n",
       "      <td>9.781446e+12</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011.0</td>\n",
       "      <td>A Visit from the Goon Squad</td>\n",
       "      <td>Jennifer Egan</td>\n",
       "      <td>Pulitzer Prize for Fiction</td>\n",
       "      <td>Winner</td>\n",
       "      <td>0231545401</td>\n",
       "      <td>4/18/2011</td>\n",
       "      <td>9.780232e+12</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013.0</td>\n",
       "      <td>The Orphan Master's Son</td>\n",
       "      <td>Adam Johnson</td>\n",
       "      <td>Pulitzer Prize for Fiction</td>\n",
       "      <td>Winner</td>\n",
       "      <td>0231557450</td>\n",
       "      <td>4/15/2013</td>\n",
       "      <td>9.780232e+12</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014.0</td>\n",
       "      <td>The Goldfinch</td>\n",
       "      <td>Donna Tartt</td>\n",
       "      <td>Pulitzer Prize for Fiction</td>\n",
       "      <td>Winner</td>\n",
       "      <td>3656925348</td>\n",
       "      <td>4/14/2014</td>\n",
       "      <td>9.783657e+12</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>Little Brother</td>\n",
       "      <td>Cory Doctorow</td>\n",
       "      <td>Nebula Award</td>\n",
       "      <td>Shortlist</td>\n",
       "      <td>1473231930</td>\n",
       "      <td>5/2/2009</td>\n",
       "      <td>9.781473e+12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1376</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>Cauldron</td>\n",
       "      <td>Jack McDevitt</td>\n",
       "      <td>Nebula Award</td>\n",
       "      <td>Shortlist</td>\n",
       "      <td>1472203305</td>\n",
       "      <td>5/2/2009</td>\n",
       "      <td>9.781472e+12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1377</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>Brasyl</td>\n",
       "      <td>Ian McDonald</td>\n",
       "      <td>Nebula Award</td>\n",
       "      <td>Shortlist</td>\n",
       "      <td>0575087358</td>\n",
       "      <td>5/2/2009</td>\n",
       "      <td>9.780575e+12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>Making Money</td>\n",
       "      <td>Terry Pratchett</td>\n",
       "      <td>Nebula Award</td>\n",
       "      <td>Shortlist</td>\n",
       "      <td>1407034014</td>\n",
       "      <td>5/2/2009</td>\n",
       "      <td>9.781407e+12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1379</th>\n",
       "      <td>2009.0</td>\n",
       "      <td>Superpowers</td>\n",
       "      <td>David J. Schwartz</td>\n",
       "      <td>Nebula Award</td>\n",
       "      <td>Shortlist</td>\n",
       "      <td>1407013416</td>\n",
       "      <td>5/2/2009</td>\n",
       "      <td>9.781407e+12</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>563 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        year                        title             author  \\\n",
       "0     2009.0             Olive Kitteridge   Elizabeth Strout   \n",
       "1     2010.0                      Tinkers       Paul Harding   \n",
       "2     2011.0  A Visit from the Goon Squad      Jennifer Egan   \n",
       "3     2013.0      The Orphan Master's Son       Adam Johnson   \n",
       "4     2014.0                The Goldfinch        Donna Tartt   \n",
       "...      ...                          ...                ...   \n",
       "1375  2009.0               Little Brother      Cory Doctorow   \n",
       "1376  2009.0                     Cauldron      Jack McDevitt   \n",
       "1377  2009.0                       Brasyl       Ian McDonald   \n",
       "1378  2009.0                 Making Money    Terry Pratchett   \n",
       "1379  2009.0                  Superpowers  David J. Schwartz   \n",
       "\n",
       "                           price Shortlist/Longlist/Winner     ISBN-10  \\\n",
       "0     Pulitzer Prize for Fiction                    Winner  140006208X   \n",
       "1     Pulitzer Prize for Fiction                    Winner  1446455998   \n",
       "2     Pulitzer Prize for Fiction                    Winner  0231545401   \n",
       "3     Pulitzer Prize for Fiction                    Winner  0231557450   \n",
       "4     Pulitzer Prize for Fiction                    Winner  3656925348   \n",
       "...                          ...                       ...         ...   \n",
       "1375                Nebula Award                 Shortlist  1473231930   \n",
       "1376                Nebula Award                 Shortlist  1472203305   \n",
       "1377                Nebula Award                 Shortlist  0575087358   \n",
       "1378                Nebula Award                 Shortlist  1407034014   \n",
       "1379                Nebula Award                 Shortlist  1407013416   \n",
       "\n",
       "           date       ISBN-13  month  \n",
       "0     4/20/2009  9.781400e+12     28  \n",
       "1     4/12/2010  9.781446e+12     40  \n",
       "2     4/18/2011  9.780232e+12     52  \n",
       "3     4/15/2013  9.780232e+12     76  \n",
       "4     4/14/2014  9.783657e+12     88  \n",
       "...         ...           ...    ...  \n",
       "1375   5/2/2009  9.781473e+12     29  \n",
       "1376   5/2/2009  9.781472e+12     29  \n",
       "1377   5/2/2009  9.780575e+12     29  \n",
       "1378   5/2/2009  9.781407e+12     29  \n",
       "1379   5/2/2009  9.781407e+12     29  \n",
       "\n",
       "[563 rows x 9 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "year                         float64\n",
       "title                         object\n",
       "author                        object\n",
       "price                         object\n",
       "Shortlist/Longlist/Winner     object\n",
       "ISBN-10                       object\n",
       "date                          object\n",
       "ISBN-13                      float64\n",
       "month                          int64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "price_df = pd.read_csv(\"datasets/Buchpreise_2009-2024.csv\")\n",
    "\n",
    "def comp_months(df):\n",
    "    split_date = df['date'].str.split(\"/\")\n",
    "    df['year'] = pd.to_numeric(split_date.str[-1], errors='coerce', downcast='integer')\n",
    "\n",
    "    df['month'] = pd.to_numeric(split_date.str[0], errors='coerce', downcast='integer')\n",
    "\n",
    "    # Compute months since December 2006\n",
    "    df['month'] = ((df['year'] - 2006) * 12) + (df['month'] - 12)\n",
    "\n",
    "    return df\n",
    "\n",
    "price_df = comp_months(price_df)\n",
    "price_df = price_df.dropna(subset=['title'])\n",
    "price_df = price_df[price_df['year'] < 2016]\n",
    "price_df['month'] = price_df['month'].astype(int)\n",
    "\n",
    "\n",
    "display(price_df)\n",
    "display(price_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def find_matched_controls(winner_row, control_books, win_month, n_neighbors=100):\n",
    "    \"\"\"\n",
    "    Find control books using kNN based on normalized pre-win reviews and transformed review slope.\n",
    "    \"\"\"\n",
    "    win_month -= 1 #to exclude direct effects of winning the prize\n",
    "    \n",
    "    # Clip small negative _lrc values to zero (handle rounding noise)\n",
    "    winner_lrc = max(winner_row[f'_lrc_{win_month}'], 0)\n",
    "    \n",
    "    # Use .loc to avoid SettingWithCopyWarning\n",
    "    control_books.loc[:, f'_lrc_{win_month}_clipped'] = control_books[f'_lrc_{win_month}'].clip(lower=0)\n",
    "    \n",
    "    # Apply log transformation to _lrc (add a small constant to avoid log(0))\n",
    "    epsilon = 1e-6\n",
    "    winner_lrc_log = np.log(winner_lrc + epsilon)\n",
    "    control_books.loc[:, f'_lrc_{win_month}_log'] = np.log(control_books[f'_lrc_{win_month}_clipped'] + epsilon)\n",
    "    \n",
    "    # Extract features for winner\n",
    "    winner_features = np.array([\n",
    "        winner_row[f'_int_{win_month}'],  # Pre-win reviews (cumulative)\n",
    "        winner_lrc_log                    # Transformed slope\n",
    "    ]).reshape(1, -1)\n",
    "    \n",
    "    # Extract features for controls\n",
    "    control_features = control_books[[\n",
    "        f'_int_{win_month}', \n",
    "        f'_lrc_{win_month}_log'\n",
    "    ]].values\n",
    "    \n",
    "    # Normalize features using MinMaxScaler\n",
    "    scaler = MinMaxScaler()\n",
    "    control_features_scaled = scaler.fit_transform(control_features)\n",
    "    winner_features_scaled = scaler.transform(winner_features)\n",
    "    \n",
    "    # Fit kNN model on scaled features\n",
    "    nn = NearestNeighbors(n_neighbors=n_neighbors, metric=\"euclidean\").fit(control_features_scaled)\n",
    "    _, indices = nn.kneighbors(winner_features_scaled)\n",
    "    \n",
    "    # Return matched controls\n",
    "    return control_books.iloc[indices.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dowhy import CausalModel\n",
    "\n",
    "# Define columns\n",
    "int_columns = [col for col in df.columns if col.startswith('_int_')]\n",
    "slope_columns = [col for col in df.columns if col.startswith('_lrc_')]\n",
    "\n",
    "def analyze_prize_impact(df, price_df, prize_name=None):\n",
    "    \"\"\"\n",
    "    Analyze the impact of winning a prize on review counts using causal inference.\n",
    "    Only important metrics (ATE, confidence intervals) are stored and printed.\n",
    "    \"\"\"\n",
    "    # Filter winners\n",
    "    winners = price_df[price_df['Shortlist/Longlist/Winner'] == 'Winner'].copy()\n",
    "    winners['title'] = winners['title'].str.strip().str.lower()\n",
    "    \n",
    "    if prize_name:\n",
    "        winners = winners[winners['price'] == prize_name]\n",
    "    \n",
    "    # Separate winners and controls\n",
    "    winner_books = df[df['title'].isin(winners['title'])]\n",
    "    control_books = df[~df['title'].isin(winners['title'])].copy()\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for _, winner in winners.iterrows():\n",
    "        title = winner['title']\n",
    "        win_month = winner['month']\n",
    "        \n",
    "        # Skip if winner book not found\n",
    "        if title not in winner_books['title'].values:\n",
    "            print(f\"Book '{title}' not found in dataset.\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare winner's time series\n",
    "        winner_row = winner_books[winner_books['title'] == title].iloc[0]\n",
    "        winner_ts = pd.DataFrame({\n",
    "            'date': range(len(int_columns)),\n",
    "            'reviews': winner_row[int_columns].values\n",
    "        })\n",
    "        \n",
    "        # Match controls using kNN\n",
    "        matched_controls = find_matched_controls(winner_row, control_books, win_month)\n",
    "        \n",
    "        if matched_controls.empty:\n",
    "            print(f\"No matched controls found for book '{title}'.\")\n",
    "            continue\n",
    "        \n",
    "        # Combine winner and control data\n",
    "        control_ts = pd.DataFrame({\n",
    "            f'ctrl_reviews_{i}': matched_controls.iloc[i][int_columns].values\n",
    "            for i in range(len(matched_controls))\n",
    "        })\n",
    "        analysis_df = pd.concat([winner_ts, control_ts], axis=1).dropna()\n",
    "        \n",
    "        # Validate columns\n",
    "        valid_cols = [\n",
    "            col for col in analysis_df.columns\n",
    "            if analysis_df[col].nunique() > 1 and analysis_df[col].std() > 0\n",
    "        ]\n",
    "        analysis_df = analysis_df[valid_cols]\n",
    "        \n",
    "        if 'reviews' not in analysis_df.columns or len(analysis_df.columns) < 2:\n",
    "            print(f\"Insufficient valid data for book '{title}'.\")\n",
    "            continue\n",
    "        \n",
    "        # Define treatment variable\n",
    "        analysis_df['treatment_dummy'] = (analysis_df['date'] >= win_month).astype(int)\n",
    "        \n",
    "        # Causal inference (reviews impact)\n",
    "        try:\n",
    "            print(\"starting inference\")\n",
    "            reviews_model = CausalModel(\n",
    "                data=analysis_df,\n",
    "                treatment='treatment_dummy',\n",
    "                outcome='reviews',\n",
    "                common_causes=[col for col in analysis_df.columns if col.startswith('ctrl_reviews')],\n",
    "                time_variable='date'\n",
    "            )\n",
    "            identified_estimand = reviews_model.identify_effect()\n",
    "            causal_estimate = reviews_model.estimate_effect(\n",
    "                identified_estimand,\n",
    "                method_name=\"backdoor.propensity_score_weighting\",\n",
    "                confidence_intervals=True\n",
    "            )\n",
    "            \n",
    "            # Extract key metrics\n",
    "            ate = causal_estimate.value  # Average Treatment Effect\n",
    "            ci_low, ci_high = causal_estimate.get_confidence_intervals()\n",
    "            # Print results\n",
    "            print(f\"Results for book '{title}':\")\n",
    "            print(f\"  ATE: {ate:.4f}\")\n",
    "            print(f\"  Confidence Interval: [{ci_low:.4f}, {ci_high:.4f}]\")\n",
    "            print(\"\\n\" + \"-\"*10 + \"\\n\")\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'title': title,\n",
    "                'ATE': ate,\n",
    "                'CI_low': ci_low,\n",
    "                'CI_high': ci_high\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing book '{title}': {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pulitzer Prize for Fiction',\n",
       " 'National Book Award',\n",
       " 'Hugo Award',\n",
       " 'Deutscher Buchpreis',\n",
       " 'Booker Prize',\n",
       " 'Literature Nobel Prize',\n",
       " 'Goodreads Choice Awards',\n",
       " \"Women's Prize for Fiction\",\n",
       " 'National Book Award for Fiction',\n",
       " 'Nebula Award']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing prize: Pulitzer Prize for Fiction\n",
      "starting inference\n",
      "Results for book 'olive kitteridge':\n",
      "  ATE: 1232.1681\n",
      "  Confidence Interval: [1137.6543, 1331.6055]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'tinkers':\n",
      "  ATE: 491.1962\n",
      "  Confidence Interval: [455.4413, 526.9518]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'a visit from the goon squad':\n",
      "  ATE: 2038.6247\n",
      "  Confidence Interval: [1933.1562, 2136.5208]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the orphan master's son':\n",
      "  ATE: 928.5993\n",
      "  Confidence Interval: [875.7534, 983.0122]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the goldfinch':\n",
      "  ATE: 5241.8000\n",
      "  Confidence Interval: [4944.7969, 5556.5908]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'all the light we cannot see':\n",
      "  ATE: 6644.1137\n",
      "  Confidence Interval: [6191.7056, 7156.5854]\n",
      "\n",
      "----------\n",
      "\n",
      "Analyzing prize: National Book Award\n",
      "starting inference\n",
      "Results for book 'let the great world spin':\n",
      "  ATE: 785.8621\n",
      "  Confidence Interval: [729.0989, 844.4435]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'shine shine shine':\n",
      "  ATE: 143.5681\n",
      "  Confidence Interval: [96.3210, 177.1244]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the sense of an ending':\n",
      "  ATE: 1610.8945\n",
      "  Confidence Interval: [1489.2293, 1748.8909]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'this is how you lose her':\n",
      "  ATE: 924.3678\n",
      "  Confidence Interval: [863.8805, 984.3215]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the goldfinch':\n",
      "  ATE: 4903.3668\n",
      "  Confidence Interval: [4469.3410, 5349.5667]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'redeployment':\n",
      "  ATE: 408.6443\n",
      "  Confidence Interval: [378.8356, 444.6789]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'between the world and me':\n",
      "  ATE: 2106.2401\n",
      "  Confidence Interval: [1924.1300, 2333.8206]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the underground railroad':\n",
      "  ATE: 1065.0384\n",
      "  Confidence Interval: [673.2113, 1465.1514]\n",
      "\n",
      "----------\n",
      "\n",
      "Analyzing prize: Hugo Award\n",
      "starting inference\n",
      "Results for book 'the graveyard book':\n",
      "  ATE: 2965.5078\n",
      "  Confidence Interval: [2717.6615, 3241.6600]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the city & the city':\n",
      "  ATE: 619.8405\n",
      "  Confidence Interval: [576.1050, 670.4425]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the windup girl':\n",
      "  ATE: 880.6966\n",
      "  Confidence Interval: [819.2644, 949.4361]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'blackout/all clear' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'among others':\n",
      "  ATE: 771.5851\n",
      "  Confidence Interval: [722.9626, 822.3637]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'redshirts: a novel with three codas':\n",
      "  ATE: 128.9725\n",
      "  Confidence Interval: [122.2002, 137.0562]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'ancillary justice' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'the three body problem':\n",
      "  ATE: 1.4028\n",
      "  Confidence Interval: [1.1392, 1.6609]\n",
      "\n",
      "----------\n",
      "\n",
      "Analyzing prize: Deutscher Buchpreis\n",
      "starting inference\n",
      "Results for book 'du stirbst nicht':\n",
      "  ATE: 1.9766\n",
      "  Confidence Interval: [1.6916, 2.2019]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'tauben fliegen auf':\n",
      "  ATE: 2.4317\n",
      "  Confidence Interval: [1.7936, 2.9603]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'in zeiten des abnehmenden lichts':\n",
      "  ATE: 0.3591\n",
      "  Confidence Interval: [0.0963, 0.5550]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'landgericht':\n",
      "  ATE: 0.7423\n",
      "  Confidence Interval: [0.6025, 0.8701]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'das ungeheuer':\n",
      "  ATE: 1.6738\n",
      "  Confidence Interval: [1.5305, 1.8026]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'kruso':\n",
      "  ATE: 7.3580\n",
      "  Confidence Interval: [6.1302, 8.7371]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'die erfindung der roten armee fraktion durch einen manisch-depressiven teenager im sommer 1969':\n",
      "  ATE: 2.2389\n",
      "  Confidence Interval: [1.8529, 2.6114]\n",
      "\n",
      "----------\n",
      "\n",
      "Analyzing prize: Booker Prize\n",
      "starting inference\n",
      "Results for book 'wolf hall':\n",
      "  ATE: 4.2364\n",
      "  Confidence Interval: [3.2543, 5.2126]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the finkler question':\n",
      "  ATE: 282.1793\n",
      "  Confidence Interval: [266.4074, 298.4903]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the sense of an ending':\n",
      "  ATE: 1610.8945\n",
      "  Confidence Interval: [1488.3348, 1752.2569]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'bring up the bodies':\n",
      "  ATE: 12.8102\n",
      "  Confidence Interval: [12.1815, 13.4977]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the luminaries':\n",
      "  ATE: 924.8663\n",
      "  Confidence Interval: [861.5011, 988.0619]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the narrow road to the deep north':\n",
      "  ATE: 704.1809\n",
      "  Confidence Interval: [647.8505, 761.0090]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'a brief history of seven killings':\n",
      "  ATE: 503.2832\n",
      "  Confidence Interval: [471.4168, 546.9749]\n",
      "\n",
      "----------\n",
      "\n",
      "Analyzing prize: Literature Nobel Prize\n",
      "starting inference\n",
      "Results for book 'the hunger angel':\n",
      "  ATE: 22.3824\n",
      "  Confidence Interval: [16.9291, 26.8743]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the fox was ever the hunter':\n",
      "  ATE: 2.9848\n",
      "  Confidence Interval: [1.6376, 4.0581]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the feast of the goat':\n",
      "  ATE: 90.4075\n",
      "  Confidence Interval: [82.7708, 99.2287]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'conversation in the cathedral':\n",
      "  ATE: 16.9811\n",
      "  Confidence Interval: [15.3443, 18.6738]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'baltic spring' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'the half-finished heaven':\n",
      "  ATE: 9.3928\n",
      "  Confidence Interval: [8.5766, 10.2836]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'red sorghum':\n",
      "  ATE: 49.9331\n",
      "  Confidence Interval: [45.6515, 53.8740]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'frog':\n",
      "  ATE: 126.9885\n",
      "  Confidence Interval: [116.2413, 139.1364]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'too much happiness':\n",
      "  ATE: 204.3203\n",
      "  Confidence Interval: [188.9518, 220.6030]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the love of a good woman':\n",
      "  ATE: 35.0080\n",
      "  Confidence Interval: [31.9155, 38.5429]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'dora bruder':\n",
      "  ATE: 60.5985\n",
      "  Confidence Interval: [52.4823, 69.8174]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'honeymoon':\n",
      "  ATE: 40.9688\n",
      "  Confidence Interval: [36.4625, 45.6677]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the unwomanly face of war':\n",
      "  ATE: 0.3828\n",
      "  Confidence Interval: [0.0086, 0.6725]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'second-hand time':\n",
      "  ATE: 4.6288\n",
      "  Confidence Interval: [2.2890, 6.4634]\n",
      "\n",
      "----------\n",
      "\n",
      "Analyzing prize: Goodreads Choice Awards\n",
      "Book 'diary of a wimpy kid: dog days' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'dead and gone':\n",
      "  ATE: 5.1076\n",
      "  Confidence Interval: [4.0462, 6.0104]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the help':\n",
      "  ATE: 6937.4129\n",
      "  Confidence Interval: [6422.2720, 7484.6263]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'batman: whatever happened to the caped crusader?':\n",
      "  ATE: 115.6119\n",
      "  Confidence Interval: [106.8718, 123.9776]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the girl who played with fire':\n",
      "  ATE: 22.2129\n",
      "  Confidence Interval: [18.2531, 26.0550]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'columbine':\n",
      "  ATE: 731.5375\n",
      "  Confidence Interval: [674.9542, 792.7540]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'an echo in the bone' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'leviathan':\n",
      "  ATE: 107.4225\n",
      "  Confidence Interval: [94.5774, 120.8162]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'along for the ride':\n",
      "  ATE: 791.1982\n",
      "  Confidence Interval: [725.9477, 860.7202]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the last song':\n",
      "  ATE: 1015.6825\n",
      "  Confidence Interval: [941.4694, 1090.5258]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'blueberry girl':\n",
      "  ATE: 105.7979\n",
      "  Confidence Interval: [97.3808, 114.9678]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'catching fire':\n",
      "  ATE: 3.1265\n",
      "  Confidence Interval: [2.2680, 3.8713]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'diary of a wimpy kid: the ugly truth' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'towers of midnight':\n",
      "  ATE: 0.9313\n",
      "  Confidence Interval: [0.5506, 1.1965]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'room':\n",
      "  ATE: 4598.1662\n",
      "  Confidence Interval: [4246.0020, 4982.9210]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the immortal life of henrietta lacks':\n",
      "  ATE: 2720.6333\n",
      "  Confidence Interval: [2520.0727, 2945.1685]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'twilight: the graphic novel' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'fall of giants':\n",
      "  ATE: 36.6084\n",
      "  Confidence Interval: [33.3872, 39.5350]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the tudors':\n",
      "  ATE: 6.7594\n",
      "  Confidence Interval: [6.1305, 7.4651]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'bite me: a love story' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'unbearable lightness':\n",
      "  ATE: 7.6817\n",
      "  Confidence Interval: [7.3676, 8.0162]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'the girl who kicked the hornets' nest' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'the immortal life of henrietta lacks':\n",
      "  ATE: 2720.6333\n",
      "  Confidence Interval: [2523.3692, 2927.2772]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'come on all you ghosts':\n",
      "  ATE: 17.2878\n",
      "  Confidence Interval: [16.3377, 18.4245]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'lover mine':\n",
      "  ATE: 3.7942\n",
      "  Confidence Interval: [3.5540, 4.0447]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'feed':\n",
      "  ATE: 662.1156\n",
      "  Confidence Interval: [610.8997, 714.4912]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'mockingjay':\n",
      "  ATE: 15.0103\n",
      "  Confidence Interval: [11.5801, 17.8060]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'before i fall':\n",
      "  ATE: 2367.0174\n",
      "  Confidence Interval: [2145.0127, 2580.6049]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'torment':\n",
      "  ATE: 29.1033\n",
      "  Confidence Interval: [25.2414, 32.9935]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'dead in the family':\n",
      "  ATE: 0.7259\n",
      "  Confidence Interval: [0.5992, 0.8643]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'it's a book':\n",
      "  ATE: 249.1104\n",
      "  Confidence Interval: [234.5142, 261.7489]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the son of neptune':\n",
      "  ATE: 13.5065\n",
      "  Confidence Interval: [12.2322, 14.5599]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'a dance with dragons':\n",
      "  ATE: 1.7998\n",
      "  Confidence Interval: [1.2758, 2.2926]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book '1q84':\n",
      "  ATE: 1714.8254\n",
      "  Confidence Interval: [1619.9549, 1824.4893]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'vampire academy: the graphic novel' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'the paris wife':\n",
      "  ATE: 1961.2577\n",
      "  Confidence Interval: [1839.5754, 2098.4472]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'steve jobs':\n",
      "  ATE: 1586.7194\n",
      "  Confidence Interval: [1493.1877, 1687.4011]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'graveminder':\n",
      "  ATE: 51.0750\n",
      "  Confidence Interval: [48.4227, 53.8665]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'bossypants':\n",
      "  ATE: 4014.1759\n",
      "  Confidence Interval: [3754.7400, 4301.6056]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'two kisses for maddy: a memoir of loss & love':\n",
      "  ATE: 13.6361\n",
      "  Confidence Interval: [12.8496, 14.4176]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'smokin' seventeen':\n",
      "  ATE: 0.7196\n",
      "  Confidence Interval: [0.5041, 0.9214]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'the geeks shall inherit the earth' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'horoscopes for the dead':\n",
      "  ATE: 60.6284\n",
      "  Confidence Interval: [56.9747, 64.3915]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'lover unleashed':\n",
      "  ATE: 0.4036\n",
      "  Confidence Interval: [0.2115, 0.5521]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book '11/22/63':\n",
      "  ATE: 3573.6197\n",
      "  Confidence Interval: [3312.4348, 3807.8010]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'divergent':\n",
      "  ATE: 1.3790\n",
      "  Confidence Interval: [0.8403, 1.8337]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'where she went':\n",
      "  ATE: 11.3844\n",
      "  Confidence Interval: [9.6935, 12.8447]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'my father's daughter':\n",
      "  ATE: 2.1642\n",
      "  Confidence Interval: [1.3746, 2.8295]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'city of fallen angels':\n",
      "  ATE: 2.2199\n",
      "  Confidence Interval: [1.3500, 2.9384]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'shadowfever' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'when i grow up':\n",
      "  ATE: 74.9075\n",
      "  Confidence Interval: [68.4446, 80.8542]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'little princes: one man's promise to bring home the lost children of nepal':\n",
      "  ATE: 265.0192\n",
      "  Confidence Interval: [251.0925, 280.5276]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the mark of athena':\n",
      "  ATE: 13.3407\n",
      "  Confidence Interval: [12.5415, 14.0880]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'the dark tower: the wind through the keyhole' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'the casual vacancy':\n",
      "  ATE: 4367.0034\n",
      "  Confidence Interval: [4184.7091, 4569.5922]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the walking dead, vol. 16: a larger world':\n",
      "  ATE: 100.5092\n",
      "  Confidence Interval: [93.0217, 107.6458]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the light between oceans':\n",
      "  ATE: 2759.5380\n",
      "  Confidence Interval: [2540.6575, 2998.6809]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the twelve':\n",
      "  ATE: 33.4857\n",
      "  Confidence Interval: [29.8784, 36.9327]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'let's pretend this never happened':\n",
      "  ATE: 113.4303\n",
      "  Confidence Interval: [106.1612, 121.5719]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'wild: from lost to found on the pacific crest trail':\n",
      "  ATE: 3519.0189\n",
      "  Confidence Interval: [3205.7793, 3810.7491]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'gone girl':\n",
      "  ATE: 14159.5836\n",
      "  Confidence Interval: [13189.1170, 15186.0131]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'quiet: the power of introverts in a world that can't stop talking':\n",
      "  ATE: 2145.9521\n",
      "  Confidence Interval: [1973.1407, 2320.1565]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'a thousand mornings':\n",
      "  ATE: 105.5611\n",
      "  Confidence Interval: [95.6460, 115.1462]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'fifty shades freed':\n",
      "  ATE: 0.8255\n",
      "  Confidence Interval: [0.6862, 0.9753]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the long earth':\n",
      "  ATE: 68.1113\n",
      "  Confidence Interval: [62.4493, 74.2285]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'insurgent':\n",
      "  ATE: 11.2968\n",
      "  Confidence Interval: [8.0234, 13.9288]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the fault in our stars':\n",
      "  ATE: 17855.2123\n",
      "  Confidence Interval: [16665.2683, 19237.9917]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the pioneer woman cooks: recipes from an accidental country girl':\n",
      "  ATE: 89.1379\n",
      "  Confidence Interval: [79.5994, 97.6469]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'insurgent':\n",
      "  ATE: 11.2968\n",
      "  Confidence Interval: [8.2926, 14.1472]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'shadow of night':\n",
      "  ATE: 16.8073\n",
      "  Confidence Interval: [15.9915, 17.6775]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'olivia and the fairy princesses':\n",
      "  ATE: 81.2333\n",
      "  Confidence Interval: [77.8105, 85.4492]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the house of hades':\n",
      "  ATE: 15.2992\n",
      "  Confidence Interval: [14.3961, 16.3158]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the ocean at the end of the lane':\n",
      "  ATE: 6617.2050\n",
      "  Confidence Interval: [6243.8873, 6972.5570]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'and the mountains echoed':\n",
      "  ATE: 2758.0383\n",
      "  Confidence Interval: [2639.5736, 2872.7554]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'tangled':\n",
      "  ATE: 103.3172\n",
      "  Confidence Interval: [92.8294, 113.8616]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'beautiful creatures':\n",
      "  ATE: 11.8674\n",
      "  Confidence Interval: [11.0580, 12.7144]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'life after life':\n",
      "  ATE: 3017.6394\n",
      "  Confidence Interval: [2863.0883, 3182.8587]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'jim henson: the biography':\n",
      "  ATE: 164.8178\n",
      "  Confidence Interval: [158.8353, 170.6600]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'doctor sleep':\n",
      "  ATE: 2159.2939\n",
      "  Confidence Interval: [2072.4941, 2242.0875]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'hyperbole & a half' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'i am malala':\n",
      "  ATE: 48.0230\n",
      "  Confidence Interval: [43.6614, 52.7903]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'inferno':\n",
      "  ATE: 145.3537\n",
      "  Confidence Interval: [132.2687, 156.9287]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the autistic brain: thinking across the spectrum':\n",
      "  ATE: 57.5789\n",
      "  Confidence Interval: [54.8022, 60.5895]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the fall of arthur':\n",
      "  ATE: 70.6786\n",
      "  Confidence Interval: [66.8213, 74.9654]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'lover at last' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'maddaddam':\n",
      "  ATE: 31.9774\n",
      "  Confidence Interval: [30.2206, 33.8298]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'allegiant':\n",
      "  ATE: 6.9935\n",
      "  Confidence Interval: [6.0321, 8.0264]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'eleanor & park':\n",
      "  ATE: 8304.0673\n",
      "  Confidence Interval: [7646.9799, 9004.3579]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'tequila mockingbird: cocktails with a literary twist':\n",
      "  ATE: 63.7867\n",
      "  Confidence Interval: [60.1039, 67.3272]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'cold days':\n",
      "  ATE: 1.6430\n",
      "  Confidence Interval: [1.2621, 1.9856]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the day the crayons quit':\n",
      "  ATE: 517.4979\n",
      "  Confidence Interval: [484.6983, 553.5128]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the blood of olympus':\n",
      "  ATE: 19.7708\n",
      "  Confidence Interval: [19.0486, 20.4998]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the book of life':\n",
      "  ATE: 12.0509\n",
      "  Confidence Interval: [10.9119, 13.4069]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'landline':\n",
      "  ATE: 3521.0407\n",
      "  Confidence Interval: [3340.5712, 3724.6770]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'red rising':\n",
      "  ATE: 5.3407\n",
      "  Confidence Interval: [4.7099, 5.9442]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'serenity: leaves on the wind' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'all the light we cannot see':\n",
      "  ATE: 6389.2780\n",
      "  Confidence Interval: [5864.6316, 6973.7052]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the romanov sisters':\n",
      "  ATE: 4.6670\n",
      "  Confidence Interval: [4.4640, 4.8953]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'prince lestat':\n",
      "  ATE: 4.4291\n",
      "  Confidence Interval: [3.7744, 5.1577]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'yes please':\n",
      "  ATE: 3671.8727\n",
      "  Confidence Interval: [3424.8549, 3929.1038]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'this star won't go out':\n",
      "  ATE: 2.4115\n",
      "  Confidence Interval: [1.9882, 2.7985]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'mr. mercedes':\n",
      "  ATE: 2.1947\n",
      "  Confidence Interval: [1.5218, 2.7071]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'the opposite of loneliness' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'lullabies':\n",
      "  ATE: 262.5674\n",
      "  Confidence Interval: [241.3780, 284.1333]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'written in my own heart's blood':\n",
      "  ATE: 6.8987\n",
      "  Confidence Interval: [6.3303, 7.5136]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the martian':\n",
      "  ATE: 9522.7036\n",
      "  Confidence Interval: [8707.6805, 10353.4442]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'city of heavenly fire' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'we were liars':\n",
      "  ATE: 7201.9183\n",
      "  Confidence Interval: [6790.5497, 7614.8049]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book '#girlboss':\n",
      "  ATE: 558.4366\n",
      "  Confidence Interval: [503.1228, 617.7740]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'make it ahead: a barefoot contessa cookbook':\n",
      "  ATE: 21.6871\n",
      "  Confidence Interval: [20.8417, 22.5895]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'the pigeon needs a bath! (i do not!)' not found in dataset.\n",
      "Book 'the sword of summer' not found in dataset.\n",
      "Book 'trigger warning: short fictions & disturbances' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'go set a watchman':\n",
      "  ATE: 3746.8642\n",
      "  Confidence Interval: [3606.8890, 3923.3114]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'red queen':\n",
      "  ATE: 65.6402\n",
      "  Confidence Interval: [58.5047, 73.5650]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'saga, volume 4':\n",
      "  ATE: 6.6916\n",
      "  Confidence Interval: [5.8202, 7.5298]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the nightingale':\n",
      "  ATE: 4275.8256\n",
      "  Confidence Interval: [4020.6002, 4551.1004]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'dead wake: the last crossing of the lusitania':\n",
      "  ATE: 1089.7846\n",
      "  Confidence Interval: [1034.7080, 1153.5686]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'saint odd':\n",
      "  ATE: 0.2452\n",
      "  Confidence Interval: [0.0883, 0.4010]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'why not me?':\n",
      "  ATE: 1596.5066\n",
      "  Confidence Interval: [1511.0770, 1724.2993]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'a work in progress':\n",
      "  ATE: 309.9375\n",
      "  Confidence Interval: [293.5943, 325.6146]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the girl on the train':\n",
      "  ATE: 13269.7780\n",
      "  Confidence Interval: [12394.9463, 14333.4173]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'modern romance: an investigation':\n",
      "  ATE: 132.0813\n",
      "  Confidence Interval: [124.8780, 138.4370]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the dogs i have kissed':\n",
      "  ATE: 54.2304\n",
      "  Confidence Interval: [48.5961, 60.8036]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'confess':\n",
      "  ATE: 2690.8463\n",
      "  Confidence Interval: [2555.3668, 2853.7268]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'golden son':\n",
      "  ATE: 34.5326\n",
      "  Confidence Interval: [28.9597, 40.0328]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'queen of shadows' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'all the bright places':\n",
      "  ATE: 4244.3643\n",
      "  Confidence Interval: [4006.7071, 4508.9888]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the pioneer woman cooks: dinnertime':\n",
      "  ATE: 1.9613\n",
      "  Confidence Interval: [1.9226, 2.0168]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the day the crayons came home':\n",
      "  ATE: 266.5746\n",
      "  Confidence Interval: [253.5580, 281.5632]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'beneath the surface: killer whales, seaworld, and the truth beyond blackfish':\n",
      "  ATE: 120.1041\n",
      "  Confidence Interval: [114.5917, 126.3359]\n",
      "\n",
      "----------\n",
      "\n",
      "Analyzing prize: Women's Prize for Fiction\n",
      "starting inference\n",
      "Results for book 'home':\n",
      "  ATE: 317.9254\n",
      "  Confidence Interval: [267.8531, 370.7113]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the lacuna':\n",
      "  ATE: 662.1672\n",
      "  Confidence Interval: [617.4179, 702.9565]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the tiger's wife':\n",
      "  ATE: 1216.7203\n",
      "  Confidence Interval: [1142.8809, 1293.1883]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the song of achilles':\n",
      "  ATE: 1080.1986\n",
      "  Confidence Interval: [948.5363, 1201.7226]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'may we be forgiven':\n",
      "  ATE: 241.4303\n",
      "  Confidence Interval: [229.2908, 256.1990]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'a girl is a half-formed thing':\n",
      "  ATE: 201.0992\n",
      "  Confidence Interval: [183.9963, 220.6114]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'how to be both':\n",
      "  ATE: 312.8173\n",
      "  Confidence Interval: [294.4773, 332.0739]\n",
      "\n",
      "----------\n",
      "\n",
      "Analyzing prize: National Book Award for Fiction\n",
      "starting inference\n",
      "Results for book 'let the great world spin':\n",
      "  ATE: 792.4349\n",
      "  Confidence Interval: [738.6878, 848.3357]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'lord of misrule':\n",
      "  ATE: 101.7697\n",
      "  Confidence Interval: [95.7883, 106.8217]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'salvage the bones':\n",
      "  ATE: 403.9979\n",
      "  Confidence Interval: [374.4460, 433.8567]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the round house':\n",
      "  ATE: 979.2653\n",
      "  Confidence Interval: [922.3870, 1043.0624]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'the good lord bird':\n",
      "  ATE: 340.4885\n",
      "  Confidence Interval: [317.9997, 364.2156]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'redeployment':\n",
      "  ATE: 416.6484\n",
      "  Confidence Interval: [391.9477, 454.9291]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'fortune smiles':\n",
      "  ATE: 175.7028\n",
      "  Confidence Interval: [162.9389, 189.2628]\n",
      "\n",
      "----------\n",
      "\n",
      "Analyzing prize: Nebula Award\n",
      "starting inference\n",
      "Results for book 'annihilation':\n",
      "  ATE: 13.0310\n",
      "  Confidence Interval: [12.2699, 13.7220]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'ancillary justice' not found in dataset.\n",
      "starting inference\n",
      "Results for book '2312':\n",
      "  ATE: 310.2449\n",
      "  Confidence Interval: [290.5708, 328.0768]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'among others':\n",
      "  ATE: 757.0468\n",
      "  Confidence Interval: [704.4360, 817.3491]\n",
      "\n",
      "----------\n",
      "\n",
      "Book 'blackout / all clear' not found in dataset.\n",
      "starting inference\n",
      "Results for book 'the windup girl':\n",
      "  ATE: 862.0170\n",
      "  Confidence Interval: [795.9310, 940.1960]\n",
      "\n",
      "----------\n",
      "\n",
      "starting inference\n",
      "Results for book 'powers':\n",
      "  ATE: 17.4985\n",
      "  Confidence Interval: [15.7886, 19.2477]\n",
      "\n",
      "----------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Get unique non-empty prizes\n",
    "unique_prizes = price_df['price'].dropna().unique().tolist()\n",
    "display(unique_prizes)\n",
    "\n",
    "# Initialize master results dictionary\n",
    "all_results = {}\n",
    "\n",
    "# Run analysis for each prize\n",
    "for prize in unique_prizes:\n",
    "    try:\n",
    "        print(f\"Analyzing prize: {prize}\")\n",
    "        prize_results = analyze_prize_impact(\n",
    "            df,\n",
    "            price_df,\n",
    "            prize_name=prize\n",
    "        )\n",
    "        \n",
    "        # Convert results to a dictionary (key: book title)\n",
    "        prize_results_dict = {result['title']: result for result in prize_results}\n",
    "        \n",
    "        # Save to master dictionary\n",
    "        all_results[prize] = prize_results_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing prize '{prize}': {e}\")\n",
    "\n",
    "# Save as JSON\n",
    "with open('outcomes/prize_impact_results.json', 'w') as f:\n",
    "    json.dump(all_results, f, default=lambda x: float(x) if isinstance(x, np.float32) else x, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
